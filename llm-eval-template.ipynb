{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/project/twohopIC/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from transformers import AutoTokenizer\n",
    "import pdb\n",
    "import json\n",
    "from scipy.stats import normaltest\n",
    "import os\n",
    "# print(os.getcwd())\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from transformers import AutoTokenizer\n",
    "import pdb\n",
    "from tqdm import tqdm\n",
    "from torch.nn import functional as F\n",
    "from src.llm_eval_configs import MODEL_OPTIONS, proto_template, short_names, mixed_locations, mixed_biology, languages\n",
    "\n",
    "from scipy.stats import normaltest\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"values that you need to change\"\"\"\n",
    "PROJECT_PATH = \".\" # the path of your working directory\n",
    "access_token = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate dataset for finetuning and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "\n",
    "# Token handling functions\n",
    "def get_token_index(tokenizer, name, model_type):\n",
    "    \"\"\"\n",
    "    Get the correct token index based on model type, handling BOS tokens appropriately\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.encode(' ' + name)\n",
    "    \n",
    "    if model_type in [\"llama3-8b\", \"llama3-70b\", \"llama3-70b\", \"llama2-7b\"]:\n",
    "        if model_type == \"llama2-7b\":\n",
    "            return tokens[2]\n",
    "        return tokens[1]  # Skip BOS token\n",
    "    elif model_type == \"olmo\":\n",
    "        return tokens[0]\n",
    "    elif model_type == \"qwen\":\n",
    "        return tokens[0]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "def process(sentence, category, names):\n",
    "    \"\"\"\n",
    "    Replaces the placeholders [A], [B], [C] in `sentence` with the given list of `names`.\n",
    "    \"\"\"\n",
    "    return (sentence\n",
    "            .replace(\"[A]\", names[0])\n",
    "            .replace(\"[B]\", names[1])\n",
    "            .replace(\"[C]\", names[2])\n",
    "           )\n",
    "\n",
    "def pick_category_and_names(template_str):\n",
    "    \"\"\"\n",
    "    Return category from template_str.\n",
    "    \"\"\"\n",
    "    if \"speak\" in template_str:\n",
    "        return \"language\"\n",
    "    elif \"city\" in template_str or \"located\" in template_str or \"time zone\" in template_str:\n",
    "        return \"geography\"\n",
    "    elif \"species\" in template_str or \"genus\" in template_str:\n",
    "        return \"biology\"\n",
    "    else:\n",
    "        return \"human\"\n",
    "\n",
    "def sample_names(category):\n",
    "    \"\"\"\n",
    "    Returns one triple of names depending on the category.\n",
    "    \"\"\"\n",
    "    if category == \"language\":\n",
    "        return [\n",
    "            random.choice(short_names),\n",
    "            random.choice(mixed_locations),\n",
    "            random.choice(languages)\n",
    "        ]\n",
    "    elif category == \"geography\":\n",
    "        return random.sample(mixed_locations, 3)\n",
    "    elif category == \"biology\":\n",
    "        return random.sample(mixed_biology, 3)\n",
    "    else:\n",
    "        return random.sample(short_names, 3)\n",
    "\n",
    "def sample_k_disjoint_sets(category, k):\n",
    "    \"\"\"\n",
    "    Returns a list of k disjoint name-triples for the given category.\n",
    "    \"\"\"\n",
    "    sets = []\n",
    "    if category == \"language\":\n",
    "        sn_candidates = random.sample(short_names, k)\n",
    "        loc_candidates = random.sample(mixed_locations, k)\n",
    "        lang_candidates = random.sample(languages, k)\n",
    "        for i in range(k):\n",
    "            sets.append([sn_candidates[i], loc_candidates[i], lang_candidates[i]])\n",
    "    \n",
    "    elif category == \"geography\":\n",
    "        loc_sample = random.sample(mixed_locations, 3*k)\n",
    "        for i in range(k):\n",
    "            sets.append(loc_sample[3*i : 3*i+3])\n",
    "    \n",
    "    elif category == \"biology\":\n",
    "        bio_sample = random.sample(mixed_biology, 3*k)\n",
    "        for i in range(k):\n",
    "            sets.append(bio_sample[3*i : 3*i+3])\n",
    "    \n",
    "    else:  # human relationship\n",
    "        sn_sample = random.sample(short_names, 3*k)\n",
    "        for i in range(k):\n",
    "            sets.append(sn_sample[3*i : 3*i+3])\n",
    "    \n",
    "    return sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(chain_nums=2):\n",
    "    # Main data generation loop\n",
    "    ft_data = {}\n",
    "\n",
    "    for model_type, model_config in MODEL_OPTIONS.items():\n",
    "        # Load tokenizer for the current model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_config[\"name\"],\n",
    "            trust_remote_code=model_config[\"trust_remote_code\"],\n",
    "            timeout=10 \n",
    "        )\n",
    "        \n",
    "        # Create tracked indices\n",
    "        all_C_entities = short_names + mixed_locations + mixed_biology + languages\n",
    "        tracked_indices = {\n",
    "            name: get_token_index(tokenizer, name, model_type) \n",
    "            for name in all_C_entities\n",
    "        }\n",
    "        \n",
    "        ft_data[model_type] = {}\n",
    "        \n",
    "        for k in range(1, chain_nums):\n",
    "            ft_data[model_type][k] = []\n",
    "            for _ in tqdm(range(1000)):\n",
    "                # Pick template and category\n",
    "                temp = random.choice(proto_template)\n",
    "                category = pick_category_and_names(temp)\n",
    "                \n",
    "                # Split template and sample names\n",
    "                sentences = temp.split(\". \")\n",
    "                k_name_sets = sample_k_disjoint_sets(category, k)\n",
    "                \n",
    "                # Create deques with processed sentences\n",
    "                all_deques = []\n",
    "                for names_i in k_name_sets:\n",
    "                    dq_i = deque([process(s, category, names_i) for s in sentences])\n",
    "                    all_deques.append((dq_i, names_i))\n",
    "                \n",
    "                # Generate text by popping from deques\n",
    "                text = \"\"\n",
    "                while any(len(dq_tuple[0]) > 1 for dq_tuple in all_deques):\n",
    "                    indices_lengths = [\n",
    "                        (idx, len(dq) - 1) \n",
    "                        for idx, (dq, _) in enumerate(all_deques) \n",
    "                        if len(dq) > 1\n",
    "                    ]\n",
    "                    \n",
    "                    total_len_minus_1 = sum(x[1] for x in indices_lengths)\n",
    "                    if total_len_minus_1 == 0:\n",
    "                        break\n",
    "                    \n",
    "                    # Weighted random choice\n",
    "                    rand_val = random.random()\n",
    "                    cumulative = 0.0\n",
    "                    chosen_idx = None\n",
    "                    for (idx_deq, l_minus_1) in indices_lengths:\n",
    "                        frac = l_minus_1 / total_len_minus_1\n",
    "                        if rand_val < cumulative + frac:\n",
    "                            chosen_idx = idx_deq\n",
    "                            break\n",
    "                        cumulative += frac\n",
    "                    \n",
    "                    if chosen_idx is not None:\n",
    "                        chosen_dq, _ = all_deques[chosen_idx]\n",
    "                        text += chosen_dq.popleft() + \". \"\n",
    "                \n",
    "                # Handle final query\n",
    "                query_idx = random.randint(0, k - 1)\n",
    "                query_dq, query_names = all_deques[query_idx]\n",
    "                \n",
    "                if len(query_dq) > 0:\n",
    "                    text += query_dq.popleft()\n",
    "                \n",
    "                # Get answer and token indices\n",
    "                ans = \" \" + query_names[-1]\n",
    "                query_names_ids = [tracked_indices[n] for n in query_names]\n",
    "                non_query_names_ids = [\n",
    "                    tracked_indices[n] \n",
    "                    for idx, (_, names) in enumerate(all_deques) \n",
    "                    if idx != query_idx \n",
    "                    for n in names\n",
    "                ]\n",
    "                \n",
    "                # Save result\n",
    "                ft_data[model_type][k].append({\n",
    "                    'question': text,\n",
    "                    'answer': ans,\n",
    "                    'query_names': query_names_ids,\n",
    "                    'non_query_names': non_query_names_ids,\n",
    "                })\n",
    "\n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(model_config[\"dirname\"], exist_ok=True)\n",
    "        \n",
    "        save_name = f\"test_short.json\" if chain_nums == 2 else f\"test_long.json\"\n",
    "        with open(os.path.join(model_config[\"dirname\"], save_name), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(ft_data[model_type], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 108705.78it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 105820.57it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 108991.09it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 102973.19it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 107076.77it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 112556.46it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 67240.12it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 48532.83it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 37777.33it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 29623.30it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 108714.24it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 69018.18it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 47904.79it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 37820.25it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 30170.72it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 111979.50it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 67326.46it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 47432.39it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 37809.34it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 28891.96it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 104729.31it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 67491.13it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 49140.10it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 37264.82it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 30289.47it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 113430.08it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 5480.83it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 49296.62it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 37900.22it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 29943.91it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_data(2)\n",
    "generate_data(6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
